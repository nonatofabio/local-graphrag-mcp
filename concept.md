Local GraphRAG MCP: Concept & Architecture1. The Core Philosophy: "One Duck to Rule Them All"The central thesis of this project is that Local Graph RAG should not require a distributed system architecture (e.g., a Python service + a Neo4j container + a ChromaDB instance).For a Model Context Protocol (MCP) server running locally on a developer's machine, the architecture must be:Single Process: No Docker containers or background services required.Single File: The entire knowledge graph, vector index, and property data live in one portable .duckdb file.Hybrid Native: It must perform Vector Search and Graph Traversal in the same engine without network overhead.We achieve this by leveraging DuckDB not just as an OLAP database, but as a multi-modal engine using three critical extensions:duckpgq (Property Graph Queries): For traversing relationships.vss (Vector Similarity Search): For semantic entry points.json: For schema-less property storage.2. The Architecture: Graph on SQLUnlike traditional Graph Databases (like Neo4j) or Python Memory Graphs (like NetworkX), we are using the SQL/PGQ standard. We do not store data in native graph structures (adjacency lists) on disk. Instead, we store data in high-performance columnar tables and "project" a graph topology onto them at runtime.The StackStorage Layer: Two standard SQL tables: NODES and EDGES.Semantic Layer: The NODES table contains a description_embedding column indexed by HNSW (via vss).Graph Layer: A CREATE PROPERTY GRAPH view maps the foreign keys in EDGES to the IDs in NODES, allowing Cypher-like syntax execution.Comparison to local_faiss_mcpFeaturelocal_faiss_mcplocal_graphrag_mcpData UnitText ChunksEntities (Nodes) & Relationships (Edges)Search MethodSemantic Similarity (Dense Retrieval)Hybrid (Semantic Entry + Graph Expansion)Context WindowReturns unrelated chunks that share keywordsReturns a connected subgraph of knowledgeIngestionSimple (Split text -> Embed)Complex (LLM extracts Entities -> Embed -> Insert)3. The Retrieval Strategy: "Anchor & Expand"In a standard vector store, you retrieve the top-k chunks. In Graph RAG, we use a two-step process handled entirely within DuckDB:Step 1: The Anchor (Vector Search)We receive a user query (e.g., "How is the Auth service connected to the DB?").We embed this query and use DuckDB's vss extension to find the Top-1 or Top-3 most semantically relevant nodes in the NODES table. These are our "Anchor Nodes."Step 2: The Expansion (Graph Traversal)Starting from the Anchor Nodes, we execute a Property Graph Query (duckpgq) to traverse the graph outwards (e.g., 2 hops).Why this matters:If you search for "Apple", a Vector store gives you docs about fruit and tech.A Graph RAG search finds the "Apple (Tech)" node and traverses to "iPhone", "Tim Cook", and "Cupertino", discarding the fruit context because it lacks the dense network of relevant connections.4. Ingestion WorkflowUnlike local_faiss_mcp, we cannot simply dump text into the tool. The "Thinking" happens before storage.Extraction: The Host LLM (Claude/GPT) reads a document.Structuring: The LLM identifies entities (Nodes) and how they interact (Edges).Tool Call: The LLM calls add_knowledge_graph(nodes=[...], edges=[...]).Embedding: The MCP server calculates embeddings only for the node descriptions/names.Storage: Data is inserted into the DuckDB tables.5. Why SQL/PGQ?We chose DuckDB + duckpgq over re-engineering a Python graph database (like ruruki or networkx) for three reasons:Performance: Python loop-based traversals are slow ($O(N^2)$). DuckDB operates in C++ and uses vectorized execution for joins.Standardization: duckpgq implements the SQL:2023 standard. We are betting on the official standard rather than custom Cypher parsers.Zero-Copy: We don't need to move data from a Vector DB to a Graph DB. They are the same table rows. 